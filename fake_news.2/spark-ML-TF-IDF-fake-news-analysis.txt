
val true_rdd = sc.textFile("hdfs://hdpmst:9000/data/True.csv")

val true_rdd1 = true_rdd.map( x => x.replaceAll("\"\"","") )

true_rdd1.saveAsTextFile("hdfs://hdpmst:9000/data/True1.csv")

val true_news = spark.read.option("inferSchema","true").option("header","true").csv("hdfs://hdpmst:9000/data/True1.csv")

true_news.show
+--------------------+--------------------+------------+------------------+
|               title|                text|     subject|              date|
+--------------------+--------------------+------------+------------------+
|As U.S. budget fi...|WASHINGTON (Reute...|politicsNews|December 31, 2017 |
|U.S. military to ...|WASHINGTON (Reute...|politicsNews|December 29, 2017 |
|Senior U.S. Repub...|WASHINGTON (Reute...|politicsNews|December 31, 2017 |
|FBI Russia probe ...|WASHINGTON (Reute...|politicsNews|December 30, 2017 |
|Trump wants Posta...|SEATTLE/WASHINGTO...|politicsNews|December 29, 2017 |
|White House, Cong...|WEST PALM BEACH, ...|politicsNews|December 29, 2017 |
|Trump says Russia...|WEST PALM BEACH, ...|politicsNews|December 29, 2017 |
|Factbox: Trump on...|The following sta...|politicsNews|December 29, 2017 |
|Trump on Twitter ...|The following sta...|politicsNews|December 29, 2017 |
|Alabama official ...|WASHINGTON (Reute...|politicsNews|December 28, 2017 |
|Jones certified U...|(Reuters) - Alaba...|politicsNews|December 28, 2017 |
|New York governor...|NEW YORK/WASHINGT...|politicsNews|December 28, 2017 |
|Factbox: Trump on...|The following sta...|politicsNews|December 28, 2017 |
|Trump on Twitter ...|The following sta...|politicsNews|December 28, 2017 |
|Man says he deliv...| (In Dec. 25 stor...|politicsNews|December 25, 2017 |
|Virginia official...|(Reuters) - A lot...|politicsNews|December 27, 2017 |
|U.S. lawmakers qu...|WASHINGTON (Reute...|politicsNews|December 27, 2017 |
|Trump on Twitter ...|The following sta...|politicsNews|December 26, 2017 |
|U.S. appeals cour...|(Reuters) - A U.S...|politicsNews|December 26, 2017 |
|Treasury Secretar...|(Reuters) - A gif...|politicsNews|December 24, 2017 |
+--------------------+--------------------+------------+------------------+
only showing top 20 rows


val fake_rdd = sc.textFile("hdfs://hdpmst:9000/data/Fake.csv")

val fake_rdd1 = fake_rdd.map( x => x.replaceAll("\"\"","") )

fake_rdd1.saveAsTextFile("hdfs://hdpmst:9000/data/Fake1.csv")                                                                                
val fake_news = spark.read.option("inferSchema","true").option("header","true").csv("hdfs://hdpmst:9000/data/Fake1.csv")

fake_news.show
+--------------------+--------------------+-------+-----------------+
|               title|                text|subject|             date|
+--------------------+--------------------+-------+-----------------+
| Donald Trump Sen...|Donald Trump just...|   News|December 31, 2017|
| Drunk Bragging T...|House Intelligenc...|   News|December 31, 2017|
| Sheriff David Cl...|On Friday, it was...|   News|December 30, 2017|
| Trump Is So Obse...|On Christmas day,...|   News|December 29, 2017|
| Pope Francis Jus...|Pope Francis used...|   News|December 25, 2017|
| Racist Alabama C...|The number of cas...|   News|December 25, 2017|
| Fresh Off The Go...|Donald Trump spen...|   News|December 23, 2017|
| Trump Said Some ...|In the wake of ye...|   News|December 23, 2017|
| Former CIA Direc...|Many people have ...|   News|December 22, 2017|
| WATCH: Brand-New...|Just when you mig...|   News|December 21, 2017|
| Papa John?s Foun...|A centerpiece of ...|   News|December 21, 2017|
| WATCH: Paul Ryan...|Republicans are w...|   News|December 21, 2017|
| Bad News For Tru...|Republicans have ...|   News|December 21, 2017|
| WATCH: Lindsey G...|The media has bee...|   News|December 20, 2017|
| Heiress To Disne...|Abigail Disney is...|   News|December 20, 2017|
| Tone Deaf Trump:...|Donald Trump just...|   News|December 20, 2017|
| The Internet Bru...|A new animatronic...|   News|December 19, 2017|
| Mueller Spokesma...|Trump supporters ...|   News|December 17, 2017|
| SNL Hilariously ...|Right now, the wh...|   News|December 17, 2017|
| Republican Senat...|Senate Majority W...|   News|December 16, 2017|
+--------------------+--------------------+-------+-----------------+
only showing top 20 rows

 
val true_df = true_news.select(lit(1).as("label"), 'text)

val fake_df = fake_news.select(lit(0).as("label"), 'text)

val df1 = true_df.union(fake_df).where("text is not null")

df1.printSchema
root
 |-- label: integer (nullable = false)
 |-- text: string (nullable = true)

 
import org.apache.spark.ml.feature.RegexTokenizer
val tokenizer = new RegexTokenizer().setInputCol("text").setOutputCol("words").setPattern("""\W+""")
val df2 = tokenizer.transform(df1)

df2.select(explode('words).as("word")).distinct.count  // 122001

// filter out numbers and tokens that are words mixed with numbers
val filterNumbers = df2.select(explode('words).as("word")).where('word.rlike("^[0-9]*$")).distinct

// lists tokens greather one-character length
val tokenCountsFilteredSize = df2.select(explode('words).as("word")).where(length('word) === 1).distinct

// remove terms with only one-occurrence
val rareTokens = df2.select(explode('words).as("word")).groupBy('word).count.where('count === 1).select('word)

// unioned all terms to be removed
val wholeFilters = filterNumbers.union(tokenCountsFilteredSize).union(rareTokens).distinct.cache

wholeFilters.count  // 42932

wholeFilters.printSchema
root
 |-- word: string (nullable = true)
 
val removedWords = wholeFilters.select("word").map( x => x.getString(0)).collect.toArray
removedWords: Array[String] = Array(675, 07, 296, 0851, 0955, 829, 467, 8433, 971933766252421, 691, 94102, 4032, 1512, 2za4lty, amplifier, saucepans, sreynuon, koosha, campusfrom, circulates, 2jbx05v, aundrea, q40, weathervane, diringer, hoodfar, cropland, plaats, kalzony53, stipanovich, rainnwilson, oln, guridy, nimbler, veronika, cheon, condugua, unavoidably, zobe, inertial, swr2, naasan, zubaydi, yianna, tokitsukaze, reanimated, 2m3scbv, marja, farafra, bahrun, anime, dammam, lder,nurjaman, habiba, wattanavrangkul, zongxun, diodes, cuc, cergy, bava, akaidat, irreligious, phumtham, memom, utdi, cuernavaca, hirokatsu, 27j, buba, kakai, barangays, novum, andrassy, hci, laxity, photovoltaic, anb, mupyong, inimical, renouncement, lixiong, elenis, hijri_women_quarter_brain, lvarez, opter,...

// remove stop words
import org.apache.spark.ml.feature.StopWordsRemover
val enStopWords = StopWordsRemover.loadDefaultStopWords("english")
val remover = new StopWordsRemover().setStopWords(enStopWords).
setInputCol("words").
setOutputCol("filteredStopWords")
val df3 = remover.transform(df2)

// total words after stopwords removal
df3.select(explode('filteredStopWords).as("word")).distinct.count  // 121870

// remove tokens collected in removedListWords
import org.apache.spark.ml.feature.StopWordsRemover
val remover = new StopWordsRemover().setStopWords(removedWords).
setInputCol("filteredStopWords").
setOutputCol("filtered")
val df4 = remover.transform(df3)

// total words relevant for analysis
df4.select(explode('filtered).as("word")).distinct.count  // 78942

val dim = math.pow(2, 17).toInt  // 131072

import org.apache.spark.ml.feature.HashingTF
val tf = new HashingTF().setInputCol("filtered").
setOutputCol("TFOut").
setNumFeatures(dim)
val df5 = tf.transform(df4)

import org.apache.spark.ml.feature.IDF
val idf = new IDF().setInputCol("TFOut").setOutputCol("features")
val idfModel = idf.fit(df5)
val df6 = idfModel.transform(df5)

df6.printSchema
root
 |-- label: integer (nullable = false)
 |-- text: string (nullable = true)
 |-- words: array (nullable = true)
 |    |-- element: string (containsNull = true)
 |-- filteredStopWords: array (nullable = true)
 |    |-- element: string (containsNull = true)
 |-- filtered: array (nullable = true)
 |    |-- element: string (containsNull = true)
 |-- TFOut: vector (nullable = true)
 |-- features: vector (nullable = true)


val Array(trainingData, testData) = df6.randomSplit(Array(0.7,0.3),11L)

trainingData.cache
trainingData.count  // 31595

---- ML Logistic classification --------------

import org.apache.spark.ml.classification.{LogisticRegression}
val lr = new LogisticRegression
lr.setRegParam(0.01).setMaxIter(200).setFitIntercept(true)

val model = lr.fit(trainingData)
val pred = model.transform(testData).cache

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator

val bceval = new BinaryClassificationEvaluator()

bceval.evaluate(pred)  // 0.9960842357464703

val predRDD = pred.select("prediction","label").rdd.map( row => (row.getDouble(0),row.getInt(1).toDouble)).cache

predRDD.take(20)
res27: Array[(Double, Double)] = Array((1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0))

import org.apache.spark.mllib.evaluation.MulticlassMetrics
val metrics = new MulticlassMetrics(predRDD)

predRDD.filter(x => x._1 == x._2).count  // 13117
predRDD.count     // 13301
metrics.accuracy  // 0.9861664536501015

metrics.confusionMatrix
res31: org.apache.spark.mllib.linalg.Matrix =
6839.0  107.0
77.0    6278.0

---- ML Naive Bayes classification --------------

import org.apache.spark.ml.classification.NaiveBayes
val model = new NaiveBayes().fit(trainingData)

val pred = model.transform(testData).cache

import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
val evaluator = new MulticlassClassificationEvaluator().setMetricName("accuracy")

evaluator.evaluate(pred)  // 0.9417337042327645

val predRDD = pred.select("prediction","label").rdd.map( row => (row.getDouble(0),row.getInt(1).toDouble)).cache

predRDD.take(20)
res33: Array[(Double, Double)] = Array((1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (0.0,1.0), (1.0,1.0), (1.0,1.0), (1.0,1.0), (0.0,1.0), (1.0,1.0), (1.0,1.0), (0.0,1.0), (1.0,1.0), (0.0,1.0))

import org.apache.spark.mllib.evaluation.MulticlassMetrics
val metrics = new MulticlassMetrics(predRDD)

predRDD.filter(x => x._1 == x._2).count  // 12526
predRDD.count     // 13301
metrics.accuracy  // 0.9417337042327645

metrics.confusionMatrix
res37: org.apache.spark.mllib.linalg.Matrix =
6586.0  360.0
415.0   5940.0

